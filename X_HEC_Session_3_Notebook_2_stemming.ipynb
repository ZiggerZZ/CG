{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCKitpZTpISn"
   },
   "source": [
    "# Making necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3D1My5RHncNS"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "cWbZwPp6VBMi",
    "outputId": "62a2e69a-869b-4cb1-83f3-5860e803e2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/zigfridzvezdin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zigfridzvezdin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zigfridzvezdin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP library imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpT3m7C2o_Qc"
   },
   "source": [
    "# Applying the transformation we've seen to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "V-Lu49mLnke7",
    "outputId": "d5ced2c8-3d38-4309-d0ce-c9bd43d95931"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>language</th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-11 07:54:28</th>\n",
       "      <td>calme, reposant, confortable, dépaysant.</td>\n",
       "      <td>fr</td>\n",
       "      <td>jerome</td>\n",
       "      <td>5</td>\n",
       "      <td>bon séjour</td>\n",
       "      <td>[calme, reposant, confortable, depaysant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15 11:17:50</th>\n",
       "      <td>moi je vais parler aujourd'hui du service comm...</td>\n",
       "      <td>fr</td>\n",
       "      <td>sophie duhamel</td>\n",
       "      <td>1</td>\n",
       "      <td>Non professionnel</td>\n",
       "      <td>[vais, parler, aujourd hui, service, commercia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12 10:02:58</th>\n",
       "      <td>pas grand chose ne marche, ni l’internet, ni w...</td>\n",
       "      <td>fr</td>\n",
       "      <td>manuele civico</td>\n",
       "      <td>1</td>\n",
       "      <td>Pas grand chose ne marche !</td>\n",
       "      <td>[grand, chose, marche, internet, wifi, trop, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 07:52:09</th>\n",
       "      <td>parc très agréable, difficile de s'y retrouver...</td>\n",
       "      <td>fr</td>\n",
       "      <td>alain</td>\n",
       "      <td>3</td>\n",
       "      <td>Les TROIS FORETS</td>\n",
       "      <td>[parc, tres, agreable, difficile, s y, retrouv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-22 17:23:07</th>\n",
       "      <td>nous avons passé un excellent week-end, tout é...</td>\n",
       "      <td>fr</td>\n",
       "      <td>cor boonen</td>\n",
       "      <td>4</td>\n",
       "      <td>Week-end</td>\n",
       "      <td>[passe, excellent, week end, bien, entretenu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               content  \\\n",
       "2016-10-11 07:54:28           calme, reposant, confortable, dépaysant.   \n",
       "2017-09-15 11:17:50  moi je vais parler aujourd'hui du service comm...   \n",
       "2018-05-12 10:02:58  pas grand chose ne marche, ni l’internet, ni w...   \n",
       "2018-08-08 07:52:09  parc très agréable, difficile de s'y retrouver...   \n",
       "2018-11-22 17:23:07  nous avons passé un excellent week-end, tout é...   \n",
       "\n",
       "                    language            name  stars  \\\n",
       "2016-10-11 07:54:28       fr          jerome      5   \n",
       "2017-09-15 11:17:50       fr  sophie duhamel      1   \n",
       "2018-05-12 10:02:58       fr  manuele civico      1   \n",
       "2018-08-08 07:52:09       fr           alain      3   \n",
       "2018-11-22 17:23:07       fr      cor boonen      4   \n",
       "\n",
       "                                           title  \\\n",
       "2016-10-11 07:54:28                   bon séjour   \n",
       "2017-09-15 11:17:50            Non professionnel   \n",
       "2018-05-12 10:02:58  Pas grand chose ne marche !   \n",
       "2018-08-08 07:52:09             Les TROIS FORETS   \n",
       "2018-11-22 17:23:07                     Week-end   \n",
       "\n",
       "                                                                tokens  \n",
       "2016-10-11 07:54:28          [calme, reposant, confortable, depaysant]  \n",
       "2017-09-15 11:17:50  [vais, parler, aujourd hui, service, commercia...  \n",
       "2018-05-12 10:02:58  [grand, chose, marche, internet, wifi, trop, i...  \n",
       "2018-08-08 07:52:09  [parc, tres, agreable, difficile, s y, retrouv...  \n",
       "2018-11-22 17:23:07      [passe, excellent, week end, bien, entretenu]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataFrame\n",
    "df = pd.read_json('session_3_notebook_2.json')\n",
    "\n",
    "# Preparing transformations for preprocessing function\n",
    "caracters_to_remove = list(string.punctuation)\n",
    "transformation_car_dict = {initial:\" \" for initial in caracters_to_remove}\n",
    "\n",
    "with_accent = ['é', 'è', 'ê', 'à', 'ù', 'ç', 'ô', 'î']\n",
    "without_accent = ['e', 'e', 'e', 'a', 'u', 'c', 'o', 'i']\n",
    "transformation_accent_dict = {before:after for before, after in zip(with_accent, without_accent)}\n",
    "\n",
    "stopW = stopwords.words('french')\n",
    "stopW += ['les', 'a', 'tout']\n",
    "\n",
    "\n",
    "# Preprocessing function to apply to the content column\n",
    "def preprocessing(review):\n",
    "  \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(review)\n",
    "    \n",
    "    # Deleting words with  only one caracter\n",
    "    tokens = [token for token in tokens if len(token)>2]\n",
    "    \n",
    "    # stopwords + lowercase\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stopW]   \n",
    "    \n",
    "    # Removing accents\n",
    "    tokens = [token.translate(str.maketrans(transformation_accent_dict)) for token in tokens]\n",
    "    \n",
    "    # Deleting specific caracters\n",
    "    tokens = [token.translate(str.maketrans(transformation_car_dict)) for token in tokens]\n",
    "        \n",
    "    return tokens\n",
    "  \n",
    "\n",
    "# Creating a new column swith tokenized reviews\n",
    "df['tokens'] = df['content'].apply(preprocessing)\n",
    "\n",
    "# Displaying part of the result\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-WARsCeo-JL"
   },
   "source": [
    "# Discovering [Stemming](https://en.wikipedia.org/wiki/Stemming) and [Lemmatisation](https://en.wikipedia.org/wiki/Lemmatisation)\n",
    "\n",
    "\n",
    "If you want to understand how the [Porter Algorithm](https://fr.wikipedia.org/wiki/Racinisation#Algorithme_de_Porter) works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Stemmer objects\n",
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-2VUwd4kKL2"
   },
   "source": [
    "## Visualizing the effects of two different stemmers on basic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EHK8XvxD3v_G",
    "outputId": "83c80b3a-2efa-4860-b12e-4bb9119d8b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Porter Stemmer      lancaster Stemmer   \n",
      "friend              friend              friend              \n",
      "friendship          friendship          friend              \n",
      "friends             friend              friend              \n",
      "friendships         friendship          friend              \n",
      "stabil              stabil              stabl               \n",
      "destabilize         destabil            dest                \n",
      "misunderstanding    misunderstand       misunderstand       \n",
      "railroad            railroad            railroad            \n",
      "moonlight           moonlight           moonlight           \n",
      "football            footbal             footbal             \n"
     ]
    }
   ],
   "source": [
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,porter.stem(word),lancaster.stem(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMc4hDBnkT8n"
   },
   "source": [
    "## Effects on a total sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zVE0VoS4Pp9"
   },
   "outputs": [],
   "source": [
    "def stemSentence(sentence, stemmer):\n",
    "    \n",
    "    token_words = word_tokenize(sentence)\n",
    "    stem_sentence = []\n",
    "    \n",
    "    for word in token_words:\n",
    "        stem_sentence.append(stemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    \n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FZsE-n21lxwN",
    "outputId": "b98b81ae-f78e-4fcb-f355-5869d5e4c1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ar very intellig and work very python and now they ar python their way to success . \n",
      "python are veri intellig and work veri pythonli and now they are python their way to success . \n"
     ]
    }
   ],
   "source": [
    "# And compare differences\n",
    "sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\"\n",
    "\n",
    "print(stemSentence(sentence, lancaster))\n",
    "print(stemSentence(sentence, porter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Qcbb5PYKlzCD",
    "outputId": "ec9de27e-88be-4900-e74d-038a1e6dfd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce matin je sui allé achet un galet à la boulangery pui je me sui régalé av de venir en cour . \n",
      "Ce matin je sui allé achet une galett à la boulangeri pui je me sui régalé avant de venir en cour . \n"
     ]
    }
   ],
   "source": [
    "# Look at what is happening on a french sentence\n",
    "sentence=\"Ce matin je suis allé acheter une galette à la boulangerie puis je me suis régalé avant de venir en cours.\"\n",
    "\n",
    "print(stemSentence(sentence, lancaster))\n",
    "print(stemSentence(sentence, porter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxILJkRnkeZ2"
   },
   "source": [
    "## A stemmer to use on different languages (for example french..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iMi9p7VH4Rbx",
    "outputId": "7a5d169f-762b-481c-931f-840bcba2895b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cet phras est à la fois amus et surpren '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frenchStemSentence(sentence):\n",
    "    frenchStemmer=SnowballStemmer(\"french\", ignore_stopwords=False)\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(frenchStemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "frenchStemSentence(\"cette phrase est à la fois amusante et surprenante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELSBOPDTorCM"
   },
   "source": [
    "## Having a look at lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y3nNOH9FWpM8",
    "outputId": "d52954c5-07b4-4e07-b46e-857ee852db7e"
   },
   "outputs": [],
   "source": [
    "# Initiate lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create lematizing function\n",
    "def lemmatize(sentence):\n",
    "    tokens=word_tokenize(sentence)\n",
    "    tokens = [lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(token,pos='a'),pos='v'),pos='n') for token in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# And display results\n",
    "lemmer = lemmatize(\"Such an analysis can reveal features that are not easily visible from the variations in the individual genes and can lead to a picture of expression that is more biologically transparent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Such an analysis can reveal feature that be not easily visible from the variation in the individual gene and can lead to a picture of expression that be more biologically transparent'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUN-NholwS3a"
   },
   "source": [
    "# Applying one of those modification to our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VP7Tn1Uy4tj"
   },
   "source": [
    " **Preparing both functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14FnlWXwoum9"
   },
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(tokens):\n",
    "    tokens = [lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(token,pos='a'),pos='v'),pos='n') for token in tokens]\n",
    "    return tokens  \n",
    "\n",
    "# Stemming\n",
    "frenchStemmer=SnowballStemmer(\"french\")\n",
    "def stem(tokens):\n",
    "    tokens = [frenchStemmer.stem(token) for token in tokens]\n",
    "    return tokens  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZHHZdbjzBlI"
   },
   "source": [
    "**Selecting which one to apply, given the language used in your reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZIv9DttzLml"
   },
   "outputs": [],
   "source": [
    "# Are your reviews in English ? (here it is unfortunately not the case)\n",
    "english = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9VkIu1_zO2Z"
   },
   "source": [
    "**And finally applying it to our dataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "3QRw4_nLySif",
    "outputId": "c2bd7108-eb38-4b0a-b388-92eeef98393e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>language</th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>inflected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-23 18:56:04</th>\n",
       "      <td>expérience moyenne</td>\n",
       "      <td>fr</td>\n",
       "      <td>james james</td>\n",
       "      <td>1</td>\n",
       "      <td>4 jours au bois les francs</td>\n",
       "      <td>[experience, moyenne]</td>\n",
       "      <td>[experient, moyen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-23 20:05:44</th>\n",
       "      <td>une rivière sauvage annoncée et non présenté</td>\n",
       "      <td>fr</td>\n",
       "      <td>victor miguel</td>\n",
       "      <td>3</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>[riviere, sauvage, annoncee, non, presente]</td>\n",
       "      <td>[rivier, sauvag, annonce, non, present]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-24 09:11:08</th>\n",
       "      <td>très beau domaine mais pêchant par de nombreux...</td>\n",
       "      <td>fr</td>\n",
       "      <td>frederic lefebvre</td>\n",
       "      <td>4</td>\n",
       "      <td>Lac de l'ailette - Centerparcs</td>\n",
       "      <td>[tres, beau, domaine, pechant, nombreux, petit...</td>\n",
       "      <td>[tre, beau, domain, pech, nombreux, petit, det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-24 10:14:25</th>\n",
       "      <td>pas de problème pour parcourir le site, une ré...</td>\n",
       "      <td>fr</td>\n",
       "      <td>christian briola</td>\n",
       "      <td>5</td>\n",
       "      <td>un site plutôt pratique et agréable.</td>\n",
       "      <td>[probleme, parcourir, site, reservation, effec...</td>\n",
       "      <td>[problem, parcour, sit, reserv, effectue, quel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-24 11:47:54</th>\n",
       "      <td>location premium 6 personnes vue sur le lac, t...</td>\n",
       "      <td>fr</td>\n",
       "      <td>patricia jamet</td>\n",
       "      <td>3</td>\n",
       "      <td>beau parc, belle vue, mais quelques remarques ...</td>\n",
       "      <td>[location, premium, personnes, vue, lac, trop,...</td>\n",
       "      <td>[locat, premium, person, vu, lac, trop, beau, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               content  \\\n",
       "2014-12-23 18:56:04                                 expérience moyenne   \n",
       "2014-12-23 20:05:44       une rivière sauvage annoncée et non présenté   \n",
       "2014-12-24 09:11:08  très beau domaine mais pêchant par de nombreux...   \n",
       "2014-12-24 10:14:25  pas de problème pour parcourir le site, une ré...   \n",
       "2014-12-24 11:47:54  location premium 6 personnes vue sur le lac, t...   \n",
       "\n",
       "                    language               name  stars  \\\n",
       "2014-12-23 18:56:04       fr        james james      1   \n",
       "2014-12-23 20:05:44       fr      victor miguel      3   \n",
       "2014-12-24 09:11:08       fr  frederic lefebvre      4   \n",
       "2014-12-24 10:14:25       fr   christian briola      5   \n",
       "2014-12-24 11:47:54       fr     patricia jamet      3   \n",
       "\n",
       "                                                                 title  \\\n",
       "2014-12-23 18:56:04                         4 jours au bois les francs   \n",
       "2014-12-23 20:05:44                                              Moyen   \n",
       "2014-12-24 09:11:08                     Lac de l'ailette - Centerparcs   \n",
       "2014-12-24 10:14:25               un site plutôt pratique et agréable.   \n",
       "2014-12-24 11:47:54  beau parc, belle vue, mais quelques remarques ...   \n",
       "\n",
       "                                                                tokens  \\\n",
       "2014-12-23 18:56:04                              [experience, moyenne]   \n",
       "2014-12-23 20:05:44        [riviere, sauvage, annoncee, non, presente]   \n",
       "2014-12-24 09:11:08  [tres, beau, domaine, pechant, nombreux, petit...   \n",
       "2014-12-24 10:14:25  [probleme, parcourir, site, reservation, effec...   \n",
       "2014-12-24 11:47:54  [location, premium, personnes, vue, lac, trop,...   \n",
       "\n",
       "                                                             inflected  \n",
       "2014-12-23 18:56:04                                 [experient, moyen]  \n",
       "2014-12-23 20:05:44            [rivier, sauvag, annonce, non, present]  \n",
       "2014-12-24 09:11:08  [tre, beau, domain, pech, nombreux, petit, det...  \n",
       "2014-12-24 10:14:25  [problem, parcour, sit, reserv, effectue, quel...  \n",
       "2014-12-24 11:47:54  [locat, premium, person, vu, lac, trop, beau, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making appropriate modification\n",
    "if english:\n",
    "    df['inflected'] = df['tokens'].apply(lemmatize)\n",
    "\n",
    "else:\n",
    "    df['inflected'] = df['tokens'].apply(stem)\n",
    "\n",
    "# And displaying results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6faNnlpH3L8-"
   },
   "source": [
    "# Final modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "wsQgbDCUpSGG",
    "outputId": "7b238486-e3c6-468c-98d5-d2c693e723b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>inflected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr</td>\n",
       "      <td>james james</td>\n",
       "      <td>1</td>\n",
       "      <td>[jour, bois, franc]</td>\n",
       "      <td>[experient, moyen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr</td>\n",
       "      <td>victor miguel</td>\n",
       "      <td>3</td>\n",
       "      <td>[moyen]</td>\n",
       "      <td>[rivier, sauvag, annonce, non, present]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr</td>\n",
       "      <td>frederic lefebvre</td>\n",
       "      <td>4</td>\n",
       "      <td>[lac, l ailet, centerparc]</td>\n",
       "      <td>[tre, beau, domain, pech, nombreux, petit, det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr</td>\n",
       "      <td>christian briola</td>\n",
       "      <td>5</td>\n",
       "      <td>[sit, plutot, pratiqu, agreabl]</td>\n",
       "      <td>[problem, parcour, sit, reserv, effectue, quel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr</td>\n",
       "      <td>patricia jamet</td>\n",
       "      <td>3</td>\n",
       "      <td>[beau, parc, bel, vu, quelqu, remarqu,    ]</td>\n",
       "      <td>[locat, premium, person, vu, lac, trop, beau, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fr</td>\n",
       "      <td>duboc</td>\n",
       "      <td>5</td>\n",
       "      <td>[rien, signal]</td>\n",
       "      <td>[aucun, souc, reserv, pai, prix, interess, res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fr</td>\n",
       "      <td>donin de rosiere</td>\n",
       "      <td>3</td>\n",
       "      <td>[cottag, rafraich, urgenc]</td>\n",
       "      <td>[c et, deuxiem, fois, allion, centrerparc, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fr</td>\n",
       "      <td>semeteys</td>\n",
       "      <td>5</td>\n",
       "      <td>[tre, facil, utilis]</td>\n",
       "      <td>[sit, tre, facil, reserv, c est, fait, tre, ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fr</td>\n",
       "      <td>robert weber</td>\n",
       "      <td>4</td>\n",
       "      <td>[problem, particuli, sauf, cet, odeur, tabac]</td>\n",
       "      <td>[parf, san, cet, desagre, odeur, tabac, vrai, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fr</td>\n",
       "      <td>gualicia</td>\n",
       "      <td>4</td>\n",
       "      <td>[prec]</td>\n",
       "      <td>[lor, recherch, bien, clair, sit, reserv, sup,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language               name  stars  \\\n",
       "0       fr        james james      1   \n",
       "1       fr      victor miguel      3   \n",
       "2       fr  frederic lefebvre      4   \n",
       "3       fr   christian briola      5   \n",
       "4       fr     patricia jamet      3   \n",
       "5       fr              duboc      5   \n",
       "6       fr   donin de rosiere      3   \n",
       "7       fr           semeteys      5   \n",
       "8       fr       robert weber      4   \n",
       "9       fr           gualicia      4   \n",
       "\n",
       "                                           title  \\\n",
       "0                            [jour, bois, franc]   \n",
       "1                                        [moyen]   \n",
       "2                     [lac, l ailet, centerparc]   \n",
       "3                [sit, plutot, pratiqu, agreabl]   \n",
       "4    [beau, parc, bel, vu, quelqu, remarqu,    ]   \n",
       "5                                 [rien, signal]   \n",
       "6                     [cottag, rafraich, urgenc]   \n",
       "7                           [tre, facil, utilis]   \n",
       "8  [problem, particuli, sauf, cet, odeur, tabac]   \n",
       "9                                         [prec]   \n",
       "\n",
       "                                           inflected  \n",
       "0                                 [experient, moyen]  \n",
       "1            [rivier, sauvag, annonce, non, present]  \n",
       "2  [tre, beau, domain, pech, nombreux, petit, det...  \n",
       "3  [problem, parcour, sit, reserv, effectue, quel...  \n",
       "4  [locat, premium, person, vu, lac, trop, beau, ...  \n",
       "5  [aucun, souc, reserv, pai, prix, interess, res...  \n",
       "6  [c et, deuxiem, fois, allion, centrerparc, pre...  \n",
       "7  [sit, tre, facil, reserv, c est, fait, tre, ra...  \n",
       "8  [parf, san, cet, desagre, odeur, tabac, vrai, ...  \n",
       "9  [lor, recherch, bien, clair, sit, reserv, sup,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why not doing the same on title \n",
    "df['title'] = df['title'].apply(preprocessing).apply(stem)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Finally keeping only necessary columns\n",
    "del(df['content'])\n",
    "del(df['tokens'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "X_HEC_Session_3_Notebook_2_stemming.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
